# Proposed Reading / Presentations
## 2020 Winter
  * [Learning Symbolic Physics with Graph Networks](https://arxiv.org/abs/1909.05862)
Closely related to [Interaction Networks for Learning about Objects, Relations and Physics](https://arxiv.org/abs/1612.00222). See also [NeurIPS talk](https://slideslive.com/38922576/learning-symbolic-physics-with-graph-networks)

  * [Quantum Algorithms for Deep Convolutional Neural Networks](https://scirate.com/arxiv/1911.01117) , Iordanis Kerenidis, Jonas Landman, Anupam Prakash
Quantum algorithm to "mimic" (?) convolutional NN, i.e. including non-linearity.

  * [Cost-Function-Dependent Barren Plateaus in Shallow Quantum Neural Networks](https://scirate.com/arxiv/2001.00550)     M. Cerezo, Akira Sone, Tyler Volkoff, Lukasz Cincio, Patrick J. Coles
Extension to the previous [Barren plateau result](https://arxiv.org/abs/1803.11173). Essentially all QNN (i.e. including shallow ones) suffer from Barren plteaus (BP) when using non-local/global cost functions. Details for deep (BP), intermediate and shallow (trainable) circuits with local cost functions.

 * [Data re-uploading for a universal quantum classifier](https://quantum-journal.org/papers/q-2020-02-06-226/)
 Adrián Pérez-Salinas Alba Cervera-Lierta Elies Gil-Fuster, and José I. Latorre

 * [Recurrent Neural Network Wavefunctions](https://arxiv.org/pdf/2002.02973.pdf)     Mohamed Hibat-Allah, Martin Ganahl, Lauren E. Hayward, Roger G. Melko, Juan Carrasquilla ;; Seems recurrent networks have reached the quantum community :-)
 
 * [The Lottery Ticket Hypothesis: finding sparse,trainable neural networks](https://arxiv.org/pdf/1803.03635.pdf) 
 Jonathan Frankle, Michael Carbin
 Who will win the lottery next week?
 
 ## Archive
 
  * [Deep Learning for Symbolic Mathematics](https://arxiv.org/abs/1912.01412v1) Guillaume Lample, François Charton
Symbolid integration and solving ODEs with seq2seq models (i.e. transformers). Introductory web articles [1](https://towardsdatascience.com/transformers-141e32e69591) & [2](https://towardsdatascience.com/day-1-2-attention-seq2seq-models-65df3f49e263) as well as a nice [demonstration of its capabilities (w/ critical assessment)](https://thegradient.pub/gpt2-and-the-nature-of-intelligence/)
